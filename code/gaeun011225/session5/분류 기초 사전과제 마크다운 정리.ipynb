{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95816e8e-43ca-40f8-86d5-e2871b668d65",
   "metadata": {},
   "source": [
    "## 1. 지도 학습과 비지도 학습의 차이점\n",
    "+ <font color=\"green\">**지도 학습**</font>\n",
    "  + 정답이 있는 데이터를 사용해 예측값을 이미 만들어둔 정답과 같아지도록 기계를 학습시키는 방법\n",
    "  + (ex) 회귀: 주어진 데이터를 기반으로 정답을 잘 맞추는 함수를 찾는 문제\n",
    "  + 분류 : 기존 데이터가 어떤 레이블에 속하는지 패턴을 알고리즘으로 인지한 뒤, 새롭게 관측된 데이터에 대해 레이블을 판별\n",
    "+ <font color=\"green\">**비지도 학습**</font>\n",
    "  + 정답이 없는 데이터를 사용해 기계가 스스로 데이터 속의 패턴 또는 각 데이터 간의 유사도를 학습하도록 하는 방법\n",
    "  + 인간의 개입이 없는 데이터를 스스로 학습함\n",
    "  + (ex) 군집화: 비슷한 데이터를 묶어 큰 단위로 만들기 / 밀도 추정: 데이터 분포를 예측 / 차원 축소: 데이터 차원을 간추림\n",
    "    \n",
    "## 2. 회귀와 분류의 차이점\n",
    "둘 다 입력 값과 함께 결과 값(정답 레이블)을 같이 주고 학습시키는 **지도 학습**이지만 차이점이 존재함.\n",
    "+ <font color=\"green\">**회귀**</font>\n",
    " : 데이터가 연속형 변수를 예측하기 위해 사용됨\n",
    "+ <font color=\"green\">**분류**</font>\n",
    "  : 데이터가 범주형 변수를 예측하기 위해 사용됨\n",
    "  \n",
    "## 3. 분류모델의 네 가지 종류 + 각 모델에 대한 정리\n",
    "1. <font color=\"green\">**로지스틱 회귀**\n",
    "   : 이진 분류 문제를 해결하는 데 적합함, 독립 변수의 선형 조합에 로지스틱 함수를 적용해 출력값을 0에서 1 사이로 변환해주는 것\n",
    "   + <u>[이진 분류를 다중 선형회귀로 풀려고 할 때]</u> 직선을 사용하면 분류 작업이 제대로 작동하지 않기에 출력이 0과 1 사이의 값을 가지면서 S자 형태로 그려지는 함수를 사용해야함.<br>\n",
    "   -> **시그모이드 함수** 사용\n",
    "   + <u>[시그모이드 함수]</u> 출력이 0과 1 사이의 값을 가지면서 S자 형태로 그려지는 함수, 이진 분류작업에 적용할 수 있음, 시그모이드 함수의 적합한 가중치를 구하는 것이 중요\n",
    "    \n",
    "2. <font color=\"green\">**결정 나무**\n",
    "   : 조건에 따라 데이터를 분류해, 최종적으로 데이터가 순수한 label의 집합으로 구성될 때까지 분류를 반복하는 모델\n",
    "   + <u>[CART 알고리즘]</u> 가장 대표적인 결정 나무 알고리즘, 데이터셋을 임계값을 기준으로 두 child로 나누는 알고리즘\n",
    "     : 임계값 설정, 불순도 감소 알고리즘을 통해 불순도가 낮아지는 방향으로 설정 / 모수 설정, 차이점 시각화, Prunning을 고려해 학습 진행해야함\n",
    "     \n",
    "3. <font color=\"green\">**서포트 벡터 머신**\n",
    "   : 클래스를 분류할 수 있는 다양한 경계선 중 최적의 라인을 찾아내는 알고리즘\n",
    "   + Support vector, Decision Boundary, Margin으로 구성됨\n",
    "   + SVM은 Margin(거리)가 가장 큰 경우를 선택해 최적의 선을 찾음 (결정 경계는 데이터로부터 가장 멀리 떨어져 있는게 좋기 때문에)\n",
    "     \n",
    "4. <font color=\"green\">**KNN**\n",
    "   : 데이터로부터 거리가 가까운 k개의 다른 데이터 레이블을 참조해 분류하는 알고리즘 (비슷한 특성을 가진 데이터끼리 서로 가까이 있다는 점을 이용함)\n",
    "   + 데이터 준비 -> K값 설정 -> 거리 계산 -> 가장 가까운 K개의 이웃 선택 -> 분류 과정을 거쳐 진행\n",
    "   + KNN은 어떠한 학습도 필요하지 않음, 새로운 데이터가 왔을 때 즉석에서 주변 데이터를 이용해 classify함\n",
    "    \n",
    "## 4. 분류 평가 지표\n",
    "1. <font color=\"green\">**혼동 행렬**\n",
    "+ 분류 모델의 예측 결과를 정확한 예측과 잘못된 예측으로 구분해 나타낸 표\n",
    "+ 예측 성공여부(T/F) + 예측값(P/N)으로 구분해 총 4종류의 경우의 수 존재\n",
    "+ 혼동 행렬을 이용해 분류 모델 평가지표(정확도, 정밀도, 재현도) 나타낼 수 있음\n",
    "+ <u>정확도</u>: (TP+TN)/(TP+TN+FP+FN),  <u>정밀도</u>: TP/(TP+FP),  <u>재현도</u>: TP/(TP+FN)\n",
    "\n",
    "2. <font color=\"green\">**F1-Score**\n",
    "+ = <u>2*(정밀도와 재현율을 곱한 값) / (정밀도+재현울)</u>\n",
    "+ 정밀도와 재현율의 조화 평균\n",
    "+ 머신러닝 모델의 성능을 평가하는 주요지표\n",
    "+ 정밀도와 재현율 간의 균형을 효과적으로 평가하기 위해 조화평균 사용\n",
    "\n",
    "3. <font color=\"green\">**ROC / AUC Curve**\n",
    "+ <u>ROC curve:</u> 얼마나 분류가 잘 되었는지를 보여주는 그래프 / TRR: 참인 것들 중에 참이라고 예측한 비율 / FRR: 거짓인 것들 중에 참이라고 잘못 예측한 비율\n",
    "+ <u>AUC curve:</u> ROC와 x축 사이의 면적(적분값) / 1에 가까울 수록 분류 성능이 좋은 것이라고 파악\n",
    "\n",
    "4. <font color=\"green\">**다중 분류 평가 지표**\n",
    "+ 1,2,3은 모두 이진 분류 평가지표임 / 다중 분류 평가지표는 위 이진 분류 평가지표를 클래스별로 점수를 구한 뒤, 이를 적절히 평균을 내리는 것\n",
    "+ <u>Marco average, Weighted average, Micro average</u>가 존재함\n",
    "  \n",
    "## 5. 하이퍼파라미터 최적화\n",
    "+ <u>[하이퍼 파라미터]</u> 학습 시작 전에 사용자가 직접 설정하는 변수\n",
    "+ <u>[하이퍼 파라미터 최적화]</u> Tuning을 거쳐 적절한 하이퍼파라미터를 찾아 모델 성능을 향상시키는 것\n",
    "+ 하이퍼 파라미터 탐색범위 설정 -> 평가지표 계산 함수 정의 -> 샘플링한 하이퍼 파라미터 사용해 검증 데이터로 정확도 평가 -> 위 단계를 반복해 정확도 결과를 활용해 하이퍼 파라미터 범위를 좁힘\n",
    "+ <u>하이퍼파라미터 최적화 방법)</u> Grid Search, Random Search, Bayesian Optimization\n",
    "  + Grid Search: 정해진 범위에서 하이퍼파라미터를 **모두** 순회해 가장 좋은 성능을 내는 값을 찾는 기법\n",
    "  + Random Search: 정해진 범위에서 하이퍼파라미터를 **무작위로** 탐색해 가장 좋은 성능을 내는 값을 찾는 기법\n",
    "  + Bayesian Optimization: **사전정보**를 바탕으로 최적 하이퍼파라미터를 **확률적으로 추정**해 찾는 기법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bedbb1d-d564-41e1-bfa0-79079ee09602",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
